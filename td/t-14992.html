<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="keywords" content="Maximum number of records to be inserted with 1 commit, baan,baanerp,erp,forum,discussion,bulletin board" />
	<meta name="description" content="[Archive] Maximum number of records to be inserted with 1 commit Tools Development" />
	
	<title>Maximum number of records to be inserted with 1 commit [Archive]  - Baanboard.com</title>
	<link rel="stylesheet" type="text/css" href="../styles.css" />
</head>
<body>
<div class="pagebody">
<div id="navbar"><a href="../index.html">Newbaanboard</a> &gt; <a href="../index.html">Baan Quick Support: Functional &amp; Technical</a> &gt; <a href="../index.html">Tools Development</a> &gt; Maximum number of records to be inserted with 1 commit</div>
<hr />
<div class="pda"></div>

<hr />

<div class="post"><div class="posttop"><div class="username">baan_fun</div><div class="date">8th April 2004, 18:03</div></div><div class="posttext">Hi,<br />
<br />
Is there a maximum limit of the number of records to be inserted in a table as 1 transaction with 1 commit?<br />
<br />
Myself I would need to store in one transaction app. 15.000 records. In the end I don't need the commit. I'll use abort. <br />
<br />
I need this functionality to build a logic for an array. Accordingly with a logic some records have to be stored in a list. During some later checks they could be taken out this list. <br />
<br />
I'm trying to avoid to check every time each element of the array and then move the array to left if an element was taken out.<br />
<br />
Is there any other logic than using a temp table to do db.insert for each record to be stored and db.delete for each record to be taken out from the list?<br />
<br />
Thanks and regards.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">NPRao</div><div class="date">8th April 2004, 19:52</div></div><div class="posttext">Do complete your user profile with regards to the Baan software version, Database software and OS version. This will help other members when diagnosing your problem. <br />
<br />
http://www.baanboard.com/baanboard/usercp.php?s=<br />
<br />
Is there a maximum limit of the number of records to be inserted in a table as 1 transaction with 1 commit?<br />
Here is some information -<br />
<br />
BaanERP Application Software Engineering Guides<br />
 <br />
Size of database transactions<br />
--------------------------------------------------------------------------------<br />
Problem<br />
For optimal performance, database transactions must not be too small and not too large. However they must always be logical transactions.<br />
<br />
Large transactions will also have relatively long locking times. Depending on the frequency of updates done by other users, this can cause locking problems.<br />
<br />
Other problems can also occur, for example, run-time tools (bshell, driver, and so on) consume more memory and CPU, more rollback segments are needed in the RDBMS.<br />
<br />
Solution<br />
If possible, do not implement the commit.transaction()for each single update. On the other hand, if possible, do not implement the commit.transaction() for too many updates.<br />
<br />
It is difficult to give hard numbers for this. The optimal transaction size depends on many factors. <br />
Currently a general rule can be about 100 to 250 updates per commit. (The commit rate). Apply these numbers only if the chances are small that other users update the same records.<br />
<br />
Example<br />
Bad situation: one commit per updatedb.retry.point()<br />
<br />
select	table.*<br />
from	table for update<br />
order by table._index1 with retry<br />
selectdo<br />
	...<br />
	db.update(table, db.retry)<br />
	commit.transaction()<br />
endselect<br />
Bad situation: commit for (more than) 1000 updates<br />
<br />
db.retry.point()<br />
select	table.*<br />
from	table for update <br />
selectdo		|* table can have more than<br />
	...		|* 1000 rows !<br />
       db.update(table, db.retry)<br />
endselect<br />
commit.transaction()<br />
Improved: commit per 100 updates<br />
<br />
long      number.of.updates<br />
 <br />
db.retry.point()<br />
number.of.updates = 0<br />
select	table.*<br />
from	table for update<br />
order by table._index1 with retry<br />
selectdo<br />
	...<br />
	db.update(table, db.retry)<br />
	number.of.updates = number.of.updates + 1<br />
	if number.of.updates = 100 then<br />
		commit.transaction()<br />
		number.of.updates = 0<br />
	endif<br />
selecteos<br />
	commit.transaction()<br />
endselect<br />
The selecteos section with the commit.transaction() is needed. It will be explained in help page 'implementation of selecteos'.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Marc van Kessel</div><div class="date">8th April 2004, 22:37</div></div><div class="posttext">&gt; I'm trying to avoid to check every time each <br />
&gt; element of the array and then move the array <br />
&gt; to left if an element was taken out.<br />
<br />
If you have to define a new table anyway then <br />
you might just as well commit the records and<br />
execute deletes instead of an abort.transaction. <br />
You can add the process-Id (pid) to the table<br />
index to keep the 'arrays' of different users <br />
seprated. <br />
<br />
If you know that the maximum number of entries is<br />
limited I would consider staying with arrays.<br />
Possible suggestions:<br />
- keep a special array to keep track of removed<br />
entries and do not move the array<br />
- make entries empty in stead of removing them<br />
<br />
Best regards,<br />
Marc</div></div><hr />


<div class="post"><div class="posttop"><div class="username">JaapJD</div><div class="date">9th April 2004, 09:49</div></div><div class="posttext">You can add the process-Id (pid) to the table index to keep the 'arrays' of different users separated <br />
Don't use pid, because this is the internal process id within the bshell. It is not unique for each user. Use bshell.pid() instead of this.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">NPRao</div><div class="date">9th April 2004, 23:48</div></div><div class="posttext">I need this functionality to build a logic for an array. Accordingly with a logic some records have to be stored in a list. During some later checks they could be taken out this list.  <br />
You can consider to use qss.search() and qss.sort() options.<br />
<br />
Searching and sorting data overview and synopsis (http://www.baanboard.com/programmers_manual_baanerp_help_functions_searching_sorting_data_overview_and_synopsis) <br />
<br />
sorting sample programs (http://www.baanboard.com/programmers_manual_baanerp_help_functions_searching_sorting_data_example) <br />
<br />
qss.search() (http://www.baanboard.com/programmers_manual_baanerp_help_functions_searching_sorting_data_qss_search) <br />
<br />
qss.sort() (http://www.baanboard.com/programmers_manual_baanerp_help_functions_searching_sorting_data_qss_sort)</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baan_fun</div><div class="date">13th April 2004, 11:27</div></div><div class="posttext">Please find below my comments. <br />
<br />
Replys for NPRao's Posts:<br />
-Thanks a lot for your answer<br />
- sorry about my profile. Since I'm working in environments for 4b2 to 5c I didn't know which one to put. I'll specify the details in posts<br />
- thanks for partial docu. I'm quite familiar with it<br />
- I know also the qss functions. As I already specified the performance is a big issue in this program (actually I'm optimizing an already existing script). I had the feeling that using db.insert for array elements that I need to store and db.delete for the ones I want out it will be the faster way to do (I get the sort and the search in one step).<br />
<br />
Do you think that the performance given by qss.search(), store or take out element from array and qss.sort()  can be compared with db.insert as performace? Please let me know your opinion.<br />
<br />
Replys for Marc van Kessel:<br />
-Thanks a lot for your answer<br />
- I'm trying to avoid commit.transaction() for performance reasons. I have to fill, sort and do a query for this array (that can have sometimes up to 15.000 elements) in less than 2sec.<br />
-The process ID is indeed unique only for one bshell.<br />
- Set on empty the array elements that i want out : this is what I'm doing for the moment but it's eating performane since my array gets sometimes to have 200 elements and 198 are empty.<br />
<br />
Replys for Jaap JD:<br />
-Thanks a lot for your answer<br />
<br />
<br />
<br />
Looking forward to your posts.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">NPRao</div><div class="date">13th April 2004, 21:29</div></div><div class="posttext">Do you think that the performance given by qss.search(), store or take out element from array and qss.sort() can be compared with db.insert as performace? Please let me know your opinion. <br />
You have to test it and validate which one is better design using - mtime() (http://www.baanboard.com/programmers_manual_baanerp_help_functions_timers_mtime) <br />
If you are using array you are limited by the size -<br />
This allocates memory space to the specified variable at run time (up to a maximum of 5Mb). The variable can be a string or an array (of any type). <br />
But if you are using a table then you are not limited by the number of records. But you should come up with good design for the fields and indexes. Also depends on if its a common/shared company or a company specific table, tracking by user id or process run.<br />
- Set on empty the array elements that i want out : this is what I'm doing for the moment but it's eating performane since my array gets sometimes to have 200 elements and 198 are empty. <br />
You can always keep a track of the array size and resize it up or down.<br />
 I want out it will be the faster way to do (I get the sort and the search in one step). <br />
Alternatively you can put all the values into a file and you can use the BaaN or Unix sort-<br />
 <br />
[DEV:bsp]/app/lms/bin&gt;sort6.2 -?<br />
Usage: sort [-qe error-file] [-funbirdcmt'x'] [+beg_pos[-fnbird]] [-end_pos]] [-{o|qo} outfile] [file] ...  <br />
To find the pattern in the file, you can use the function in the library - ottdllfilehand<br />
 pattern.in.file<br />
long pattern.in.file( const string file(), const string pattern() )<br />
pre: true<br />
desc: 1: The pattern is in the file<br />
      0: The pattern is not in the file.<br />
      &lt; 0: An error occurred. Probably the file cannot be read.<br />
<br />
Be aware that is not a perfect pattern match, but a partial match.<br />
<br />
Good Luck... :p</div></div><hr />



</div>
</body>
</html>