<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="keywords" content="Backup Server, baan,baanerp,erp,forum,discussion,bulletin board" />
	<meta name="description" content="[Archive] Backup Server Tools Administration &amp; Installation" />
	
	<title>Backup Server [Archive]  - Baanboard.com</title>
	<link rel="stylesheet" type="text/css" href="../styles.css" />
</head>
<body>
<div class="pagebody">
<div id="navbar"><a href="../index.html">Newbaanboard</a> &gt; <a href="../index.html">Baan Quick Support: Functional &amp; Technical</a> &gt; <a href="../index.html">Tools Administration &amp; Installation</a> &gt; Backup Server</div>
<hr />
<div class="pda"></div>

<hr />

<div class="post"><div class="posttop"><div class="username">nileshsamsonite</div><div class="date">22nd January 2007, 10:58</div></div><div class="posttext">Hi,<br />
<br />
We are creating sequential Dump from the live server. It tooks around 5/6 hrs. For that we have scheduled the job which runs at night. The sequential dump files size is around 18 GB.<br />
After creating the sequential dump we are creating table from sequential dump on a backup server. This we do once in a week as the creation of table from sequnetial dump tooks 40 hrs.<br />
<br />
We want to optimize this restoration time. <br />
Pls help how and what steps or configuration needs to be set on the backup server.<br />
Or is there any alternet method.<br />
<br />
Thanks.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">sukesh75</div><div class="date">22nd January 2007, 12:00</div></div><div class="posttext">It would help if you give the hardware specs of both these servers.. <br />
<br />
sk</div></div><hr />


<div class="post"><div class="posttop"><div class="username">nileshsamsonite</div><div class="date">22nd January 2007, 12:32</div></div><div class="posttext">Configuration :<br />
The Backup server is <br />
IBM xSeries@235	XEON 2.4 Ghz x 2,	2.5 GB RAM, 320 GB HDD <br />
<br />
The live server  is <br />
IBM xSeries@346	XEON 3.6 Ghz x2,	4 GB	4 x 146 GB + 2 x 73 GB HDD<br />
<br />
Both Servers configuration are good enough to process the 18 GB data.<br />
<br />
Nilesh</div></div><hr />


<div class="post"><div class="posttop"><div class="username">norwim</div><div class="date">23rd January 2007, 00:50</div></div><div class="posttext">Hi there,<br />
<br />
are you running one job to create the seq. dump?<br />
You will gain speed by splitting the dump task by running two or more jobs, each working on a different set of tables to be exported.<br />
Same applies to importing, although  'create tables from seq. dump' always takes much longer than 'create seq. dump of table'.<br />
Have you ever tried to sync the two systems via audit? I never tried it, but it should work.<br />
Another solution would be to create the seq. dumps, compare the files with the last set and only import the records which are new/have changed - although deleted records would have to be processed separately with a session that you have to create for this purpose. Should be possible, but never tried this too.<br />
<br />
hth<br />
<br />
Norbert</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Darren Phillips</div><div class="date">23rd January 2007, 02:24</div></div><div class="posttext">From your profile you are using informix The fastest method would be to use the native database tools what about using the unload and load option in informix</div></div><hr />


<div class="post"><div class="posttop"><div class="username">suhas-mahajan</div><div class="date">23rd January 2007, 06:10</div></div><div class="posttext">Hi Nilesh,<br />
<br />
18 GB data and 5/6 hours is too much. I think, tuning application/DB is required. We backing-up 18 GB data in only 30 min. approx. and hardware is too similar to yours i.e. HP ML570.<br />
<br />
Okay...do you know MAX_ARRAY_INSERT/FETCH? Search here...dont know it works for informix or not.<br />
<br />
regards,<br />
<br />
-Suhas</div></div><hr />


<div class="post"><div class="posttop"><div class="username">sukesh75</div><div class="date">23rd January 2007, 10:51</div></div><div class="posttext">Woa!!!<br />
Now thats what i think should be a trend setter...Care to provide exact details on your Hardware and what sort of backup tool you use and whether you use Raid?<br />
<br />
sk</div></div><hr />


<div class="post"><div class="posttop"><div class="username">suhas-mahajan</div><div class="date">23rd January 2007, 12:33</div></div><div class="posttext">I am talking about seq. backup using ARRAY INSERT/FETCH.<br />
<br />
We use RAID 10.<br />
<br />
regards,<br />
<br />
-Suhas</div></div><hr />


<div class="post"><div class="posttop"><div class="username">nileshsamsonite</div><div class="date">23rd January 2007, 14:00</div></div><div class="posttext">Hi Suhas,<br />
<br />
We are following the below steps for the restoration process<br />
<br />
1) Schedule job @ night on live server to create the sequential Dump file from table.<br />
2) Total size of these files is 18 GB.<br />
3) Copy the files to Backup server.<br />
4) Split the sequential files into 5 folders<br />
5) Delete the tables on backup server<br />
6) log out and relogin<br />
7) run the create tables from sequential dump session for these 5 folders - Seperate login per folder.<br />
8) Parameters are set as follows <br />
    a) Append if table exists<br />
    b) Disable the Domain Constraint<br />
    c) Ignore referential Integrity Constraint<br />
    d) field seperator &quot;|&quot; <br />
<br />
9) To finish the activity of creation of tables from sequential dump tooks 40 hrs. <br />
<br />
We are not doing anything on OS / Database level .<br />
How can we optimize the time through BaaN interface.<br />
<br />
thanks<br />
Nilesh</div></div><hr />


<div class="post"><div class="posttop"><div class="username">sukesh75</div><div class="date">23rd January 2007, 14:33</div></div><div class="posttext">Hi Suhas,<br />
   I hope you are talking about the baan sequential dump as the search for the keyword &quot;ARRAY INSERT/FETCH&quot; in baanboard gave me no results. Is this a setup done at the database level? It would be great if you could share how you proceed with this.. Last but not least, i take it that this is available on a SQL Server environment and not just on Oracle. <br />
<br />
<br />
sk<br />
<br />
P.S: When you say Raid 10 do you mean Raid 1 and 0?</div></div><hr />


<div class="post"><div class="posttop"><div class="username">suhas-mahajan</div><div class="date">24th January 2007, 06:42</div></div><div class="posttext">Hi Nilesh,<br />
<br />
Mentioned steps are ok but can be reduced.<br />
<br />
40 Hours is a huge time, I advice you to look into fine-and-tune your App/DB as well as hardware/network (If three-tier).<br />
<br />
We are not doing anything on OS / Database level .<br />
<br />
What's the reason not doing on OS/DB level. You should compare in terms of feasibility/time involved/accuracy/efforts/resources.<br />
<br />
Anyway, if you choose BaaN's way, you can optimise/automate it by using batch scripting and scheduler.<br />
<br />
1.Create a list of BaaN tables company wise and spool it in 000.txt text file.<br />
(You can more optimise it for not taking zero size tables and taking sharing table at only once, I dont know about SQL and Informix, but I can do for Oracle.)<br />
<br />
2.Create a batch file for setting environment variable as user / and or ARRAY FETCH / INSERT.<br />
<br />
User bdbpre - I bkp\000.txt -o bkp\dump.000 -q bkp\0.log -E bkp\0.err -C 000<br />
<br />
This will create company wise backup so you need not split later.<br />
<br />
3. Start xcopy/d/q/h/r/o/y/k/e source_data mapped_drive<br />
  Mapped drive is test server, where you would like to post it.<br />
4. Create a schedule and run this script at night.<br />
<br />
5. Similar create a batch script using bdbpost and refint (reorganise) on test server and scedule it after copying.<br />
<br />
I hope this helps.<br />
<br />
You can refer to know more - http://www.baanboard.com/baanboard/showthread.php?t=25713&amp;highlight=reorganise<br />
<br />
Hi Sukesh,<br />
<br />
Dont know, what you searched. <br />
<br />
http://www.baanboard.com/baanboard/showthread.php?t=1818&amp;highlight=MAX_ARRAY_INSERT<br />
<br />
http://www.baanboard.com/baanboard/showthread.php?t=7885&amp;highlight=MAX_ARRAY_FETCH<br />
<br />
<br />
Is this a setup done at the database level?<br />
<br />
No..BaaN App level into db_resource.<br />
<br />
When you say Raid 10 do you mean Raid 1 and 0?<br />
<br />
Yes...It's 1 (Mirroring) and 0 (Stripping).<br />
<br />
regards,<br />
<br />
-Suhas</div></div><hr />


<div class="post"><div class="posttop"><div class="username">kaukul</div><div class="date">25th January 2007, 09:09</div></div><div class="posttext">Hi,<br />
<br />
To get optimum performance for DB backup, one should use DB utilities. You can use OnBar/OnTape utilities of informix to backup 18 GB data. It will hardly take 20 minutes.<br />
To restore the backup, it will take around 50 minutes.<br />
<br />
Regards,<br />
Kaustubh</div></div><hr />


<div class="post"><div class="posttop"><div class="username">sukesh75</div><div class="date">27th January 2007, 07:55</div></div><div class="posttext">Thank you Suhas, I did go through all those threads and the information you gave. Unfortunately, i couldnt find one that is related to SQL Server as the back end. Its not a secret that Oracle Database does provide faster backups and so any application sitting on it should show similar performance.(E.g: Baan on Oracle). <br />
As of now, a Backup of 15GB takes somewhere close to 5 hours under normal circumstances. Hardware wise, we have Intel Xeon 3.06Ghz x 2(Dual processor), 3GB Ram and 3 x 146GB Storage in Raid 5, all of which are housed in a HP ML 370 case..<br />
Software wise: O.S: Win 2k3, DB : SQL 2k, Baan 4c4 SP20<br />
<br />
The backup file or the sequential dump of the company is written on the hard-disk which is then backed up on a tape later on...I am not too conversant with the Baan commands like bdbpre, bdbpost etc and so considering all these factors in mind can anyone suggest what setting should i tweak in order to get mind blowing backup and restoration speeds as mentioned in these threads...<br />
<br />
sk</div></div><hr />



</div>
</body>
</html>