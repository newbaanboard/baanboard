<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="keywords" content="Improve speed of sequential dump, baan,baanerp,erp,forum,discussion,bulletin board" />
	<meta name="description" content="[Archive] Improve speed of sequential dump Tools Administration &amp; Installation" />
	
	<title>Improve speed of sequential dump [Archive]  - Baanboard.com</title>
	<link rel="stylesheet" type="text/css" href="../styles.css" />
</head>
<body>
<div class="pagebody">
<div id="navbar"><a href="../index.html">Newbaanboard</a> &gt; <a href="../index.html">Baan Quick Support: Functional &amp; Technical</a> &gt; <a href="../index.html">Tools Administration &amp; Installation</a> &gt; Improve speed of sequential dump</div>
<hr />
<div class="pda"></div>

<hr />

<div class="post"><div class="posttop"><div class="username">kokchuan</div><div class="date">10th August 2005, 07:10</div></div><div class="posttext">Do anyone know how to improve the speed for sequential dump? my OS is Unix and oracle. My session take 5 hours to dump 4.5GB, it is normal or can be improve? By the way, the dump file can be place in other media like tape?</div></div><hr />


<div class="post"><div class="posttop"><div class="username">bkriekaard</div><div class="date">10th August 2005, 11:15</div></div><div class="posttext">You can set the system variabele RDS_FULL:<br />
<br />
export RDS_FULL=200<br />
<br />
When you can redirect your output of bdbpost (when running from command line) I think it's possible to send it via cpio to a tape device, but for better performance I think its better to export it first to disk.<br />
<br />
Bennie Kriekaard<br />
Profuse B.V.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">kokchuan</div><div class="date">10th August 2005, 12:23</div></div><div class="posttext">Sorry, I am newbie and where can I set the system variable RDS_FULL, on OS or DB?</div></div><hr />


<div class="post"><div class="posttop"><div class="username">dave_23</div><div class="date">10th August 2005, 13:34</div></div><div class="posttext">5 hours for 4.5 GB is pretty bad. I don't think it's going to be fixed by RDS_FULL, SSTS_SET_ROWS, etc.. although they're always good to set!<br />
<br />
Sounds more like an I/O problem is the filesystem your writing<br />
to NFS mounted? because that would do it.<br />
<br />
Dave</div></div><hr />


<div class="post"><div class="posttop"><div class="username">kokchuan</div><div class="date">10th August 2005, 13:47</div></div><div class="posttext">Dave, can you tell me how to set the value, at least let me try it out first. Never try never know...<br />
<br />
thank</div></div><hr />


<div class="post"><div class="posttop"><div class="username">dave_23</div><div class="date">10th August 2005, 14:01</div></div><div class="posttext">If you're using the session, and you're using the BW then it's (in your bw configuration screen under &quot;Command&quot;)<br />
<br />
-- -set SSTS_SET_ROWS=1000 -set RDS_FULL=1000 -set ORA_MAX_ARRAY_FETCH=1000 -set ORA_MAX_ARRAY_INSERT=1000<br />
<br />
Dave</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Anuraag</div><div class="date">10th August 2005, 14:27</div></div><div class="posttext">Dear kokchuan,<br />
<br />
u have to change db_resource file paramater to improve the speed for sequential dump. we have seq dump size around 11 GB. it normaly completed in 1 hour only, but my  OS is win2k3 &amp; database is oracle 9.2.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">victor_cleto</div><div class="date">10th August 2005, 16:33</div></div><div class="posttext">I assume you are doing a full company export. There are ways to improve the speed if there's no disk IO contention (no network drives/mounts) like:<br />
1. use better db_resource related parameters to increase the nr. of rows fetched<br />
2. dump on a per table basis (and not per company)<br />
3. dumping only the tables that have &gt;0 rows (a lot of the tables in a acompany are empty, you can avoid the Baan overhead of them by gathering a list from the database of the tables with rows &gt; 0 to be used in 2)<br />
4. split the list of tables (from 3) in 4 files and run 4 bdbpre, one for each list (dump in parallell, this can even be improved by spliting the dumps based on table size, so that the dump is really well balanced)<br />
<br />
Building such a thing needs some [good] knowledge of the bdbpre parameters, db_resource parameters, SQL (database) and unix shell scripting (for unix, on windows probably is a bit more dificult). Search the threads on these topics.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Brendan Shine</div><div class="date">21st September 2005, 00:17</div></div><div class="posttext">To speed up dumps, you can temporarily remove logical table links by saving of compnr file and then creating an empty one.  This way you won't get multiple copies of the same data (i.e., Item Master in company 100 is shared by both 300 and 400 so when doing bdbpre 100-400 with links in place you would get 3 copies--without links, just the 1 copy).  Just remember to put them back.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">MIALIM</div><div class="date">27th September 2005, 03:07</div></div><div class="posttext">Can you specify which area you are mentioned? It is database or in Baan? How to remove the logical table link? If not using the logical table then what should I do?<br />
<br />
Thank</div></div><hr />


<div class="post"><div class="posttop"><div class="username">victor_cleto</div><div class="date">27th September 2005, 10:59</div></div><div class="posttext">Can you specify which area you are mentioned? It is database or in Baan? How to remove the logical table link? If not using the logical table then what should I do?<br />
<br />
Carefull when playing with the logical links, and if you do not know what they are and on which table they are it's because you do not use them.<br />
Go for the approach of getting the list of the tables from the database (with count(*) &gt; 0) and use multiple bdbpre's on them - this works well for companies with or without logical links since you will be picking the real physical tables of the company, not linked ones.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Brendan Shine</div><div class="date">28th September 2005, 01:43</div></div><div class="posttext">Runtime for logical tables is $BSE/lib/compnr6.2.<br />
<br />
Regarding the above posting, it all depends on what you want to do.  In regards to taking dumps of all tables with count &gt; 0, it depends on when you take the snapshot and how (i.e., is everyone locked out or not) as sometimes tables--especially work tables--can have no data and then have some.  Also, dumping zero row tables I don't believe takes much time.<br />
<br />
If you have a multiple logistic with a single financial then you could get several copies of your integration table (for ex. tfgld410) which you only need the 1 real copy.  This can be a HUGE space savings.<br />
<br />
If no one is in the system--which is obviously the case if you have UNlinked the logical tables--then dumping them poses no big problems.  The only thing I can think of right off hand is that you have an old orphaned table that exists (i.e., table started off stand-alone and was created, then logically linked in Baan and original stand-alone table in Oracle/DB wasn't deleted before linking).  However, if the links are put back in before you bdbpost the data back in, you'll get a message that the table already exists or is linked.<br />
<br />
Hope this makes sense--if not, please post if more clarification is needed.</div></div><hr />



</div>
</body>
</html>