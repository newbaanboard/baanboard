<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="keywords" content="Re-Organize Tables/Tablespaces, baan,baanerp,erp,forum,discussion,bulletin board" />
	<meta name="description" content="[Archive] Re-Organize Tables/Tablespaces Tools Administration &amp; Installation" />
	
	<title>Re-Organize Tables/Tablespaces [Archive]  - Baanboard.com</title>
	<link rel="stylesheet" type="text/css" href="../styles.css" />
</head>
<body>
<div class="pagebody">
<div id="navbar"><a href="../index.html">Newbaanboard</a> &gt; <a href="../index.html">Baan Quick Support: Functional &amp; Technical</a> &gt; <a href="../index.html">Tools Administration &amp; Installation</a> &gt; Re-Organize Tables/Tablespaces</div>
<hr />
<div class="pda"></div>

<hr />

<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">25th April 2002, 14:30</div></div><div class="posttext">Hello all,<br />
<br />
We have Baan IV c2 with Oracle 7 as the back-end.<br />
<br />
We wan to re-organize our tables so as to reduce the fragmentation in the tables.<br />
Steps that we are planning are -<br />
1. Find out the current size of all Baan tables and indices.<br />
<br />
1. Take export of all Baan Tables at Baan level (by Create Seq. dump of tables ...)<br />
<br />
2. Drop the tables and indices at Oracle level.<br />
<br />
3. Modify ora_storage to have INITIAL equal to the current size.<br />
<br />
4. Import the tables at Baan level (by Create table from Seq. dump).<br />
<br />
<br />
Are these steps OK ? Is anything else also required ?<br />
<br />
Are there any other better and faster ways of re-organizing the tables ?<br />
<br />
Please advise.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">patvdv</div><div class="date">25th April 2002, 15:12</div></div><div class="posttext">Baaniac,<br />
<br />
You can also re-organize your tables by using the native Oracle IMP/EXP utilities. Usually this is much faster than Baan's bdbpre/bdbpost.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">25th April 2002, 15:18</div></div><div class="posttext">Thanks Pat for your prompt reply.<br />
<br />
But we have UNIX at the back-end and the file size limitation is just 2 GB. <br />
<br />
exp utility of Oracle creates just the data dumps of size &gt; 2 GB. !!<br />
So that option is not suitable. !!</div></div><hr />


<div class="post"><div class="posttop"><div class="username">victor_cleto</div><div class="date">26th April 2002, 08:58</div></div><div class="posttext">Depending on what version of oracle you have you can do two ways of export:<br />
- prior to 8i:<br />
create a list of tables (with size) and then create the PAR files with a maximum of 500 tables per file or the maximum nr. of tables before the size is 2GB<br />
- 8i or after:<br />
use the file=file1 file2 ... and filesize=x (max. size of export file(s) in bytes) parameters within exp.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">patvdv</div><div class="date">26th April 2002, 10:41</div></div><div class="posttext">Originally posted by baaniac <br />
Thanks Pat for your prompt reply.<br />
<br />
But we have UNIX at the back-end and the file size limitation is just 2 GB. <br />
<br />
exp utility of Oracle creates just the data dumps of size &gt; 2 GB. !!<br />
So that option is not suitable. !! <br />
<br />
Baaniac,<br />
<br />
Your UNIX flavour might support +2GB file systems (HP-UX, Solaris etc).</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">26th April 2002, 10:49</div></div><div class="posttext">Thanks Pat and Victor for your kind consideration.<br />
<br />
We have HP-UX 10.0 as our HP Unix server.<br />
Our vendor has confirmed that no single file can have size &gt; 2 GB. <br />
<br />
When we take export at Oracle level using exp utility for tables tfgld410, tfgld106 and tfgld418 independently, then also the size of individual dump is found to be &gt; 2 GB.<br />
<br />
And that is the main problem.<br />
<br />
Otherwise, exp and imp at Oracle level would have been useful.<br />
<br />
Thanks</div></div><hr />


<div class="post"><div class="posttop"><div class="username">patvdv</div><div class="date">26th April 2002, 10:51</div></div><div class="posttext">Originally posted by baaniac <br />
We have HP-UX 10.0 as our HP Unix server.<br />
Thanks <br />
<br />
Baaniac,<br />
<br />
I guess you are confined to using bdbpre/bdbpost then. But I would seriously consider upgrading both you Oracle and UNIX version in the near future - or at least try to convince your management of the necessity of it :)</div></div><hr />


<div class="post"><div class="posttop"><div class="username">victor_cleto</div><div class="date">26th April 2002, 12:16</div></div><div class="posttext">You still have the option to export to tape or &quot;compress on the fly&quot;. See the following link for more details: http://www.jlcomp.demon.co.uk/faq/bigexp.html</div></div><hr />


<div class="post"><div class="posttop"><div class="username">gguymer</div><div class="date">26th April 2002, 16:39</div></div><div class="posttext">Have you considered looking in Oracle's MetaLink web resource because its free to Oracle customers. It has a wealth of information on things like how to export / import data beyond the 2Gig file limit by using concatenated files, or to/from tape in UNIX. <br />
<br />
Also, please read &quot;How to Stop Defragmenting and Start Living: The Definitative Word on Fragmentation&quot; by Bhaskar Himatsingka and Juan Loaiza of Oracle. You can find it on MetaLink. It contains valuable and current defragmentation guidelines for Oracle 7 and 8. <br />
<br />
Gilbert Guymer<br />
Database Administrator<br />
Lufkin Industries, Inc.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Markus Schmitz</div><div class="date">29th April 2002, 19:09</div></div><div class="posttext">Hi baniac,<br />
<br />
You can use bdbpre/post, but especially if you have big tables, you will be doomed, because of long dump/loading times.<br />
<br />
You can speed up this times a bit by setting the environment variables &quot;ORA_MAX_ARRAY_FETCH&quot;, &quot;ORA_MAX_ARRAY_INSERT&quot;, &quot;RDS_FULL&quot;, &quot;SSTS_SET_ROWS&quot; to something like 200. <br />
<br />
<br />
But still imp/exp would be much better. How do you do it?<br />
<br />
simple: use unix pipes!<br />
<br />
create a pipe<br />
export into this pipe in the background<br />
read from this pipe with the &quot;split&quot; command to get smaller files.<br />
<br />
Works like a snap. Did it many times!<br />
<br />
Regards<br />
<br />
Markus</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">30th April 2002, 04:05</div></div><div class="posttext">Thanks everyone for your valuable suggestions.<br />
<br />
I would definitely try to implement your suggestions.<br />
<br />
Yes, upgrade to higher version with higher end servers is definitely on the cards.<br />
Till that time, we need to manage it.<br />
<br />
Thanks again.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Steve Johnson</div><div class="date">1st May 2002, 18:28</div></div><div class="posttext">Baan Oracle expert recommends MAX_ARRAY_INSERT never be greater than 10 if using Oracle 7 and less than ps 7.1c.02. At Oracle 8.1.7 (latest for 5.0b) and ps 7.1c.02 you can successfully use MAX-ARRAY_INSERT=100.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">patvdv</div><div class="date">1st May 2002, 22:21</div></div><div class="posttext">Steve,<br />
<br />
Did the Baan guy give you a reason why not use high values? In our case we were adviced to cap some of the server resource variables after stumbling on ORA-1455 errors (due to Oracle client OCI bug &lt;8.0.6)</div></div><hr />


<div class="post"><div class="posttop"><div class="username">Steve Johnson</div><div class="date">1st May 2002, 23:08</div></div><div class="posttext">Only that high values priot to 7.1c.02/8.1.7 caused DB insert failures occasionally.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">JamesV</div><div class="date">2nd May 2002, 06:53</div></div><div class="posttext">I have commonly used the larger values for bdbpre/post/reconfig without any problems.  I have had one case where a customer had to decrease the value due to a problem with running parallel inserts into the same table when using multiple bshells as a performance booster.  <br />
<br />
Anyone have any other bad experiences with this setting?<br />
<br />
--Jim</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">6th May 2002, 18:02</div></div><div class="posttext">Hello All,<br />
<br />
I just wanted to share my experience in re-Organizing tables which we completed last week-end.<br />
<br />
I.<br />
1st as was suggested, I took the export of a sample table using Oracle's EXP utility. When I checked the table definition in the export, I found that the table definition had outrageously high values of INITIAL and NEXT extents; meaning we would have run out of free space at the time of importing tables itself. !!!<br />
<br />
I checked this with some other tables in other tablespaces. But, the result was the same.<br />
<br />
After further investigations, it was found that export dump contained values from current storage of tables - dba_segments, dba_extents etc.<br />
<br />
But if you look at the way internally Oracle allocates data blocks, it is way different.<br />
<br />
So just scrapped the idea of export at Oracle level and instead, took the export at Baan level itself; but dropped tables at Oracle level.<br />
<br />
II.<br />
We had developed then our own utlity which got ideal size of tables and indexes from rowids and index_stats respectively.<br />
(I have attached that utility in this posting; which we had got years back.)<br />
<br />
III.<br />
Based upon the sizes reported, we modified ora_storage.<br />
<br />
IV.<br />
When I started importing tables using Baan's session &quot;Create Table from Dumps&quot; (ttaad4227m000), it was reducing free space not as per our expectations and was allocating more space per table.<br />
So I stopped the import and dropped the tables once again.<br />
<br />
V. <br />
Then, I tried creating tables at Baan level - session &quot;Create Tables&quot; (ttaad4230m00).<br />
And, I found the free space coming to be just as per our expectations.<br />
So just went ahead with the import.<br />
<br />
VI.<br />
Again, when I took export of newly imported tables at Oracle level, it showed values of INITIAL and NEXT extents different from the 1st export.<br />
<br />
Conclusion :-<br />
1. Oracle's export may contain very high values of INITIAL and NEXT which might be more than free space in hand.<br />
<br />
2. Creating tables 1st in Baan and then importing data saves free space more than that in directly importing data by session ttaad4227m000.<br />
<br />
Thanks</div></div><hr />


<div class="post"><div class="posttop"><div class="username">patvdv</div><div class="date">6th May 2002, 19:08</div></div><div class="posttext">Baaniac,<br />
<br />
Some comments:<br />
<br />
As to the EXP: did you export your table with compress on? In that case it is normal that your initial extent is high because it will be as just big to have your table fit into 1 extent. You can easily change the NEXT value after the import of course.<br />
What do you mean Oracle allocating blocks differently internally? Do you mean the variance between allocated and used space? <br />
<br />
As to using bdbpost: did you use 'drop table' before import when running 'Create Tables from sequential dumps'. If so then it should not make any difference whether you use 'Create Tables' first or not. Both will recreate the tables with your current ora_storage settings.</div></div><hr />


<div class="post"><div class="posttop"><div class="username">baaniac</div><div class="date">7th May 2002, 05:20</div></div><div class="posttext">Hello Pat,<br />
<br />
1.<br />
I did use compress option of exp utility.<br />
<br />
Here it is a sample of how I had used :-<br />
<br />
exp USERID=baan/baan FILE=ttdinv700001.dmp INDEXES=Y ROWS=Y CONSTRAINTS=Y COMPRESS=Y FULL=N TABLES=TTDINV700001 LOG=TTDINV700001.explog DIRECT=Y <br />
FEEDBACK=1000<br />
<br />
For above table, it gave INITIAL of size equivalent to 825M ... for just 2 million records. !!<br />
<br />
When I had tried the above command with ROWS=N just to get table definition, then also I got the same results. !!<br />
<br />
2.<br />
Yes. I had dropped the tables before starting importing.<br />
<br />
And still, I got different results with free space when I made use of directly ttaad4227m000 and first create tables in Baan and then use ttaad4227m000. !!<br />
<br />
Ideally speaking, there should not be any difference between the results of the both ways; as was rightly pointed out by you.<br />
But ...<br />
<br />
Thanks</div></div><hr />



</div>
</body>
</html>